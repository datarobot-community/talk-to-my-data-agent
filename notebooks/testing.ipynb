{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mypy: disable-error-code=\"import-not-found\"\n",
    "\n",
    "# The notebook should be executed from the project root directory\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "if \"_correct_path\" not in locals():\n",
    "    os.chdir(\"..\")\n",
    "    sys.path.append(\".\")\n",
    "    print(f\"changed dir to {Path('.').resolve()})\")\n",
    "    _correct_path = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "from utils.schema import AnalystDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"https://s3.amazonaws.com/datarobot_public_datasets/10k_diabetes_20.csv\"\n",
    "\n",
    "df = pl.read_csv(dataset_url, infer_schema_length=10000)\n",
    "\n",
    "# Create dataset dictionary\n",
    "dataset = AnalystDataset(\n",
    "    name=os.path.splitext(os.path.basename(dataset_url))[0], data=df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from utils.api import cleanse_dataframe\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "cleansed_data = await cleanse_dataframe(dataset)\n",
    "\n",
    "end = datetime.now()\n",
    "print(f\"Time taken: {end - start}\")\n",
    "analysis_data = cleansed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleansed_data.cleaning_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.api import suggest_questions\n",
    "\n",
    "suggested_questions = await suggest_questions([analysis_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.api import rephrase_message\n",
    "from utils.schema import ChatRequest\n",
    "\n",
    "question = \"What is the relationship between length of stay and readmission?\"\n",
    "chat_response = await rephrase_message(\n",
    "    messages=ChatRequest(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question + \"Please order the chart by readmission rate\",\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.api import get_dictionary\n",
    "\n",
    "dictionary = await get_dictionary(analysis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.analyst_db import AnalystDB\n",
    "\n",
    "analyst_db = await AnalystDB.create(\n",
    "    \"user_123\",\n",
    "    \".\",\n",
    "    \"chats\",\n",
    "    \"datasets\",\n",
    ")\n",
    "\n",
    "await analyst_db.register_dataset(analysis_data)\n",
    "\n",
    "await analyst_db.register_data_dictionary(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.api import run_analysis\n",
    "from utils.schema import RunAnalysisRequest\n",
    "\n",
    "analysis_request = RunAnalysisRequest(\n",
    "    dataset_names=[analysis_data.name],\n",
    "    question=chat_response,\n",
    ")\n",
    "analysis_result = await run_analysis(analysis_request, analyst_db=analyst_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from utils.api import get_business_analysis, run_charts\n",
    "from utils.schema import (\n",
    "    DataDictionary,\n",
    "    GetBusinessAnalysisRequest,\n",
    "    RunChartsRequest,\n",
    ")\n",
    "\n",
    "# Prepare requests\n",
    "chart_request = RunChartsRequest(\n",
    "    dataset=analysis_result.dataset,\n",
    "    question=chat_response,\n",
    ")\n",
    "\n",
    "business_request = GetBusinessAnalysisRequest(\n",
    "    dataset=analysis_result.dataset,\n",
    "    dictionary=DataDictionary.from_analyst_df(analysis_result.dataset.to_df()),\n",
    "    question=chat_response,\n",
    ")\n",
    "\n",
    "# Create and start tasks immediately\n",
    "charts_task = asyncio.create_task(run_charts(chart_request))\n",
    "business_task = asyncio.create_task(get_business_analysis(business_request))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.offline as pyo\n",
    "\n",
    "from utils.schema import GetBusinessAnalysisResult, RunChartsResult\n",
    "\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "tasks = [charts_task, business_task]\n",
    "\n",
    "# Wait for each task to complete\n",
    "for coro in asyncio.as_completed(tasks):\n",
    "    result = await coro\n",
    "\n",
    "    # Determine which task completed by checking the result structure\n",
    "    if isinstance(result, RunChartsResult) and (result.fig1 or result.fig2):\n",
    "        if result.fig1:\n",
    "            pyo.iplot(result.fig1)\n",
    "        if result.fig2:\n",
    "            pyo.iplot(result.fig2)\n",
    "\n",
    "    elif isinstance(result, GetBusinessAnalysisResult):\n",
    "        print(f\"Bottom Line:\\n{(result.bottom_line or '')}\")\n",
    "\n",
    "        print(f\"Additional Insights:\\n{result.additional_insights}\")\n",
    "\n",
    "        print(\"Follow-up Questions:\")\n",
    "        for q in result.follow_up_questions:\n",
    "            print(f\"- {q}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tests/models/run_analysis_result.json\", \"w\") as f:\n",
    "    f.write(analysis_result.model_dump_json(indent=4))\n",
    "with open(\"tests/models/run_charts_result.json\", \"w\") as f:\n",
    "    f.write(charts_task.result().model_dump_json(indent=4))\n",
    "with open(\"tests/models/run_business_result.json\", \"w\") as f:\n",
    "    f.write(business_task.result().model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from utils.api import get_dictionary\n",
    "from utils.database_helpers import Database\n",
    "\n",
    "db_tables = Database.get_tables()\n",
    "db_dataset_names = await Database.get_data(\n",
    "    *db_tables, analyst_db=analyst_db, sample_size=5000\n",
    ")\n",
    "\n",
    "db_datasets = await asyncio.gather(\n",
    "    *[analyst_db.get_dataset(name) for name in db_dataset_names]\n",
    ")\n",
    "db_dictionaries = await asyncio.gather(\n",
    "    *[get_dictionary(db_dataset) for db_dataset in db_datasets]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.api import suggest_questions\n",
    "\n",
    "suggested_questions = await suggest_questions(db_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suggested_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.api import run_database_analysis\n",
    "from utils.schema import RunDatabaseAnalysisRequest\n",
    "\n",
    "db_run_analysis = await run_database_analysis(\n",
    "    RunDatabaseAnalysisRequest(\n",
    "        dataset_names=[db_datasets[0].name],\n",
    "        question=\"How does loan default rate relate to type of loan?\",\n",
    "    ),\n",
    "    analyst_db=analyst_db,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_run_analysis.code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
